{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12500,"databundleVersionId":1375107,"sourceType":"competition"},{"sourceId":264758,"sourceType":"datasetVersion","datasetId":110710},{"sourceId":381604,"sourceType":"datasetVersion","datasetId":167823},{"sourceId":637160,"sourceType":"datasetVersion","datasetId":314792}],"dockerImageVersionId":25160,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Version 2 + Bug fix - thanks to @chinhuic\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\n#print(os.listdir(\"../input/nvidiaapex/repository/NVIDIA-apex-39e153a\"))\n#print(os.listdir(\"../input/glove-global-vectors-for-word-representation\"))\n#print(os.listdir(\"../input/jigsaw-unintended-bias-in-toxicity-classification\"))\n#print(os.listdir(\"../input/fasttext-crawl-300d-2m\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-07-22T01:05:54.616802Z","iopub.execute_input":"2024-07-22T01:05:54.617112Z","iopub.status.idle":"2024-07-22T01:05:54.624041Z","shell.execute_reply.started":"2024-07-22T01:05:54.617060Z","shell.execute_reply":"2024-07-22T01:05:54.623148Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Installing Nvidia Apex\n! pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ../input/nvidia-apex/repository/NVIDIA-apex-880ab92","metadata":{"execution":{"iopub.status.busy":"2024-07-22T01:05:54.625157Z","iopub.execute_input":"2024-07-22T01:05:54.625432Z","iopub.status.idle":"2024-07-22T01:08:36.049763Z","shell.execute_reply.started":"2024-07-22T01:05:54.625372Z","shell.execute_reply":"2024-07-22T01:08:36.048833Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.6/site-packages/pip/_internal/commands/install.py:207: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n  cmdoptions.check_install_build_global(options)\nCreated temporary directory: /tmp/pip-ephem-wheel-cache-i8ejgrmb\nCreated temporary directory: /tmp/pip-req-tracker-96f365dz\nCreated requirements tracker '/tmp/pip-req-tracker-96f365dz'\nCreated temporary directory: /tmp/pip-install-m3les51g\nProcessing /kaggle/input/nvidia-apex/repository/NVIDIA-apex-880ab92\n  Created temporary directory: /tmp/pip-req-build-2rhoxbah\n  Added file:///kaggle/input/nvidia-apex/repository/NVIDIA-apex-880ab92 to build tracker '/tmp/pip-req-tracker-96f365dz'\n    Running setup.py (path:/tmp/pip-req-build-2rhoxbah/setup.py) egg_info for package from file:///kaggle/input/nvidia-apex/repository/NVIDIA-apex-880ab92\n    Running command python setup.py egg_info\n    torch.__version__  =  1.0.1.post2\n    running egg_info\n    creating pip-egg-info/apex.egg-info\n    writing pip-egg-info/apex.egg-info/PKG-INFO\n    writing dependency_links to pip-egg-info/apex.egg-info/dependency_links.txt\n    writing top-level names to pip-egg-info/apex.egg-info/top_level.txt\n    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n    reading manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n    /tmp/pip-req-build-2rhoxbah/setup.py:33: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n  Source in /tmp/pip-req-build-2rhoxbah has version 0.1, which satisfies requirement apex==0.1 from file:///kaggle/input/nvidia-apex/repository/NVIDIA-apex-880ab92\n  Removed apex==0.1 from file:///kaggle/input/nvidia-apex/repository/NVIDIA-apex-880ab92 from build tracker '/tmp/pip-req-tracker-96f365dz'\nInstalling collected packages: apex\n  Created temporary directory: /tmp/pip-record-dg6bc53a\n  Running setup.py install for apex ... \u001b[?25l    Running command /opt/conda/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-req-build-2rhoxbah/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" --cpp_ext --cuda_ext install --record /tmp/pip-record-dg6bc53a/install-record.txt --single-version-externally-managed --compile\n    torch.__version__  =  1.0.1.post2\n    /tmp/pip-req-build-2rhoxbah/setup.py:33: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n\n    Compiling cuda extensions with\n    nvcc: NVIDIA (R) Cuda compiler driver\n    Copyright (c) 2005-2018 NVIDIA Corporation\n    Built on Sat_Aug_25_21:08:01_CDT_2018\n    Cuda compilation tools, release 10.0, V10.0.130\n    from /usr/local/cuda/bin\n\n    running install\n    running build\n    running build_py\n    creating build\n    creating build/lib.linux-x86_64-3.6\n    creating build/lib.linux-x86_64-3.6/apex\n    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n    creating build/lib.linux-x86_64-3.6/apex/RNN\n    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n    creating build/lib.linux-x86_64-3.6/apex/optimizers\n    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n    copying apex/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n    creating build/lib.linux-x86_64-3.6/apex/pyprof\n    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n    creating build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n    creating build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n    creating build/lib.linux-x86_64-3.6/apex/normalization\n    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n    running build_ext\n    building 'apex_C' extension\n    creating build/temp.linux-x86_64-3.6\n    creating build/temp.linux-x86_64-3.6/csrc\n    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/opt/conda/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n    building 'amp_C' extension\n    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n    building 'fused_adam_cuda' extension\n    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/fused_adam_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/fused_adam_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_adam_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda.o build/temp.linux-x86_64-3.6/csrc/fused_adam_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so\n    building 'syncbn' extension\n    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n    building 'fused_layer_norm_cuda' extension\n    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    cc1plus: warning: command line option ‘-Wstrict-prototypes’ is valid for C/ObjC but not for C++\n    /usr/local/cuda/bin/nvcc -I/opt/conda/lib/python3.6/site-packages/torch/lib/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/torch/csrc/api/include -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/TH -I/opt/conda/lib/python3.6/site-packages/torch/lib/include/THC -I/usr/local/cuda/include -I/opt/conda/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n    g++ -pthread -shared -B /opt/conda/compiler_compat -L/opt/conda/lib -Wl,-rpath=/opt/conda/lib -Wl,--no-as-needed -Wl,--sysroot=/ build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n    running install_lib\n    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\n    creating /opt/conda/lib/python3.6/site-packages/apex\n    creating /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\n    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\n    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\n    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\n    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /opt/conda/lib/python3.6/site-packages/apex/fp16_utils\n    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex\n    creating /opt/conda/lib/python3.6/site-packages/apex/RNN\n    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/RNN\n    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /opt/conda/lib/python3.6/site-packages/apex/RNN\n    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /opt/conda/lib/python3.6/site-packages/apex/RNN\n    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /opt/conda/lib/python3.6/site-packages/apex/RNN\n    creating /opt/conda/lib/python3.6/site-packages/apex/reparameterization\n    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/reparameterization\n    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /opt/conda/lib/python3.6/site-packages/apex/reparameterization\n    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /opt/conda/lib/python3.6/site-packages/apex/reparameterization\n    creating /opt/conda/lib/python3.6/site-packages/apex/optimizers\n    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/optimizers\n    copying build/lib.linux-x86_64-3.6/apex/optimizers/fp16_optimizer.py -> /opt/conda/lib/python3.6/site-packages/apex/optimizers\n    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /opt/conda/lib/python3.6/site-packages/apex/optimizers\n    creating /opt/conda/lib/python3.6/site-packages/apex/pyprof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof\n    creating /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof\n    creating /opt/conda/lib/python3.6/site-packages/apex/pyprof/parse\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/parse\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/parse\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/parse\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/parse\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/parse\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/parse\n    creating /opt/conda/lib/python3.6/site-packages/apex/pyprof/nvtx\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/nvtx\n    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/pyprof/nvtx\n    creating /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    creating /opt/conda/lib/python3.6/site-packages/apex/amp/lists\n    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/amp/lists\n    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /opt/conda/lib/python3.6/site-packages/apex/amp/lists\n    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /opt/conda/lib/python3.6/site-packages/apex/amp/lists\n    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /opt/conda/lib/python3.6/site-packages/apex/amp/lists\n    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /opt/conda/lib/python3.6/site-packages/apex/amp\n    creating /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /opt/conda/lib/python3.6/site-packages/apex/parallel\n    creating /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply\n    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply\n    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply\n    creating /opt/conda/lib/python3.6/site-packages/apex/normalization\n    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /opt/conda/lib/python3.6/site-packages/apex/normalization\n    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /opt/conda/lib/python3.6/site-packages/apex/normalization\n    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\n    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\n    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\n    copying build/lib.linux-x86_64-3.6/fused_adam_cuda.cpython-36m-x86_64-linux-gnu.so -> /opt/conda/lib/python3.6/site-packages\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/RNN/models.py to models.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/compat.py to compat.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/opt.py to opt.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/amp.py to amp.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/utils.py to utils.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/handle.py to handle.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n    byte-compiling /opt/conda/lib/python3.6/site-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n    running install_egg_info\n    running egg_info\n    creating apex.egg-info\n    writing apex.egg-info/PKG-INFO\n    writing dependency_links to apex.egg-info/dependency_links.txt\n    writing top-level names to apex.egg-info/top_level.txt\n    writing manifest file 'apex.egg-info/SOURCES.txt'\n    reading manifest file 'apex.egg-info/SOURCES.txt'\n    writing manifest file 'apex.egg-info/SOURCES.txt'\n    Copying apex.egg-info to /opt/conda/lib/python3.6/site-packages/apex-0.1-py3.6.egg-info\n    running install_scripts\n    writing list of installed files to '/tmp/pip-record-dg6bc53a/install-record.txt'\ndone\n\u001b[?25h  Removing source in /tmp/pip-req-build-2rhoxbah\nSuccessfully installed apex-0.1\nCleaning up...\nRemoved build tracker '/tmp/pip-req-tracker-96f365dz'\n1 location(s) to search for versions of pip:\n* https://pypi.org/simple/pip/\nGetting page https://pypi.org/simple/pip/\nStarting new HTTPS connection (1): pypi.org:443\nCould not fetch URL https://pypi.org/simple/pip/: connection error: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7c629e9f5c50>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution',)) - skipping\n","output_type":"stream"}]},{"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport datetime\nimport pkg_resources\nimport seaborn as sns\nimport time\nimport scipy.stats as stats\nimport gc\nimport re\nimport operator \nimport sys\nfrom sklearn import metrics\nfrom sklearn import model_selection\nimport torch\nimport torch.nn as nn\nimport torch.utils.data\nimport torch.nn.functional as F\nfrom nltk.stem import PorterStemmer\nfrom sklearn.metrics import roc_auc_score\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\nfrom tqdm import tqdm, tqdm_notebook\nimport os\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\nimport warnings\nwarnings.filterwarnings(action='once')\nimport pickle\nfrom apex import amp\nimport shutil","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2024-07-22T01:08:36.051878Z","iopub.execute_input":"2024-07-22T01:08:36.052164Z","iopub.status.idle":"2024-07-22T01:08:37.907767Z","shell.execute_reply.started":"2024-07-22T01:08:36.052119Z","shell.execute_reply":"2024-07-22T01:08:37.907057Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\ndevice=torch.device('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-07-22T01:08:37.910944Z","iopub.execute_input":"2024-07-22T01:08:37.911177Z","iopub.status.idle":"2024-07-22T01:08:37.945885Z","shell.execute_reply.started":"2024-07-22T01:08:37.911135Z","shell.execute_reply":"2024-07-22T01:08:37.945153Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"MAX_SEQUENCE_LENGTH = 220\nSEED = 1234\nEPOCHS = 1\nData_dir=\"../input/jigsaw-unintended-bias-in-toxicity-classification\"\nInput_dir = \"../input\"\nWORK_DIR = \"../working/\"\nnum_to_load=1000000                         #Train size to match time limit\nvalid_size= 100000                          #Validation Size\nTOXICITY_COLUMN = 'target'","metadata":{"execution":{"iopub.status.busy":"2024-07-22T01:08:37.947052Z","iopub.execute_input":"2024-07-22T01:08:37.947359Z","iopub.status.idle":"2024-07-22T01:08:37.983209Z","shell.execute_reply.started":"2024-07-22T01:08:37.947306Z","shell.execute_reply":"2024-07-22T01:08:37.982323Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Add the Bart Pytorch repo to the PATH\n# using files from: https://github.com/huggingface/pytorch-pretrained-BERT\npackage_dir_a = \"../input/ppbert/pytorch-pretrained-bert/pytorch-pretrained-BERT\"\nsys.path.insert(0, package_dir_a)\n\nfrom pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\nfrom pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification,BertAdam\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T01:08:37.984524Z","iopub.execute_input":"2024-07-22T01:08:37.984813Z","iopub.status.idle":"2024-07-22T01:08:39.344046Z","shell.execute_reply.started":"2024-07-22T01:08:37.984755Z","shell.execute_reply":"2024-07-22T01:08:39.343349Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n  return f(*args, **kwds)\n/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n  return f(*args, **kwds)\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:5201: ResourceWarning: unclosed file <_io.TextIOWrapper name='/root/.keras/keras.json' mode='r' encoding='UTF-8'>\n  _config = json.load(open(_config_path))\n/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Translate model from tensorflow to pytorch\nBERT_MODEL_PATH = '../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'\nconvert_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch(\n    BERT_MODEL_PATH + 'bert_model.ckpt',\nBERT_MODEL_PATH + 'bert_config.json',\nWORK_DIR + 'pytorch_model.bin')\n\nshutil.copyfile(BERT_MODEL_PATH + 'bert_config.json', WORK_DIR + 'bert_config.json')","metadata":{"execution":{"iopub.status.busy":"2024-07-22T01:08:39.345722Z","iopub.execute_input":"2024-07-22T01:08:39.346024Z","iopub.status.idle":"2024-07-22T01:08:47.982213Z","shell.execute_reply.started":"2024-07-22T01:08:39.345966Z","shell.execute_reply":"2024-07-22T01:08:47.981288Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Building PyTorch model from configuration: {\n  \"attention_probs_dropout_prob\": 0.1,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"max_position_embeddings\": 512,\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"type_vocab_size\": 2,\n  \"vocab_size\": 30522\n}\n\nConverting TensorFlow checkpoint from /kaggle/input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/bert_model.ckpt\nLoading TF weight bert/embeddings/LayerNorm/beta with shape [768]\nLoading TF weight bert/embeddings/LayerNorm/gamma with shape [768]\nLoading TF weight bert/embeddings/position_embeddings with shape [512, 768]\nLoading TF weight bert/embeddings/token_type_embeddings with shape [2, 768]\nLoading TF weight bert/embeddings/word_embeddings with shape [30522, 768]\nLoading TF weight bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_0/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_0/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_0/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_0/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_0/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_1/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_1/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_1/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_1/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_1/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_10/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_10/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_10/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_10/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_10/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_11/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_11/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_11/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_11/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_11/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_2/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_2/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_2/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_2/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_2/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_3/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_3/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_3/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_3/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_3/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_4/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_4/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_4/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_4/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_4/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_5/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_5/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_5/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_5/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_5/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_6/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_6/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_6/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_6/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_6/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_7/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_7/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_7/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_7/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_7/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_8/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_8/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_8/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_8/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_8/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_9/attention/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_9/attention/self/key/bias with shape [768]\nLoading TF weight bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_9/attention/self/query/bias with shape [768]\nLoading TF weight bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_9/attention/self/value/bias with shape [768]\nLoading TF weight bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\nLoading TF weight bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\nLoading TF weight bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\nLoading TF weight bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\nLoading TF weight bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\nLoading TF weight bert/encoder/layer_9/output/dense/bias with shape [768]\nLoading TF weight bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\nLoading TF weight bert/pooler/dense/bias with shape [768]\nLoading TF weight bert/pooler/dense/kernel with shape [768, 768]\nLoading TF weight cls/predictions/output_bias with shape [30522]\nLoading TF weight cls/predictions/transform/LayerNorm/beta with shape [768]\nLoading TF weight cls/predictions/transform/LayerNorm/gamma with shape [768]\nLoading TF weight cls/predictions/transform/dense/bias with shape [768]\nLoading TF weight cls/predictions/transform/dense/kernel with shape [768, 768]\nLoading TF weight cls/seq_relationship/output_bias with shape [2]\nLoading TF weight cls/seq_relationship/output_weights with shape [2, 768]\nInitialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'embeddings', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'embeddings', 'position_embeddings']\nInitialize PyTorch weight ['bert', 'embeddings', 'token_type_embeddings']\nInitialize PyTorch weight ['bert', 'embeddings', 'word_embeddings']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_0', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_1', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_10', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_11', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_2', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_3', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_4', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_5', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_6', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_7', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_8', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'key', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'query', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'attention', 'self', 'value', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'intermediate', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'encoder', 'layer_9', 'output', 'dense', 'kernel']\nInitialize PyTorch weight ['bert', 'pooler', 'dense', 'bias']\nInitialize PyTorch weight ['bert', 'pooler', 'dense', 'kernel']\nInitialize PyTorch weight ['cls', 'predictions', 'output_bias']\nInitialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'beta']\nInitialize PyTorch weight ['cls', 'predictions', 'transform', 'LayerNorm', 'gamma']\nInitialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'bias']\nInitialize PyTorch weight ['cls', 'predictions', 'transform', 'dense', 'kernel']\nInitialize PyTorch weight ['cls', 'seq_relationship', 'output_bias']\nInitialize PyTorch weight ['cls', 'seq_relationship', 'output_weights']\nSave PyTorch model to ../working/pytorch_model.bin\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'../working/bert_config.json'"},"metadata":{}}]},{"cell_type":"code","source":"os.listdir(\"../working\")","metadata":{"execution":{"iopub.status.busy":"2024-07-22T01:08:47.983482Z","iopub.execute_input":"2024-07-22T01:08:47.983893Z","iopub.status.idle":"2024-07-22T01:08:48.078897Z","shell.execute_reply.started":"2024-07-22T01:08:47.983831Z","shell.execute_reply":"2024-07-22T01:08:48.078156Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['pytorch_model.bin', 'bert_config.json']"},"metadata":{}}]},{"cell_type":"code","source":"# This is the Bert configuration file\nfrom pytorch_pretrained_bert import BertConfig\n\nbert_config = BertConfig('../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'+'bert_config.json')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T01:08:48.080177Z","iopub.execute_input":"2024-07-22T01:08:48.080496Z","iopub.status.idle":"2024-07-22T01:08:48.135011Z","shell.execute_reply.started":"2024-07-22T01:08:48.080436Z","shell.execute_reply":"2024-07-22T01:08:48.134134Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Converting the lines to BERT format\n# Thanks to https://www.kaggle.com/httpwwwfszyc/bert-in-keras-taming\ndef convert_lines(example, max_seq_length,tokenizer):\n    max_seq_length -=2\n    all_tokens = []\n    longer = 0\n    for text in tqdm_notebook(example):\n        tokens_a = tokenizer.tokenize(text)\n        if len(tokens_a)>max_seq_length:\n            tokens_a = tokens_a[:max_seq_length]\n            longer += 1\n        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n        all_tokens.append(one_token)\n    print(longer)\n    return np.array(all_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T01:08:48.136904Z","iopub.execute_input":"2024-07-22T01:08:48.137149Z","iopub.status.idle":"2024-07-22T01:08:48.188012Z","shell.execute_reply.started":"2024-07-22T01:08:48.137107Z","shell.execute_reply":"2024-07-22T01:08:48.187110Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"BERT_MODEL_PATH = '../input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T01:08:48.189517Z","iopub.execute_input":"2024-07-22T01:08:48.189830Z","iopub.status.idle":"2024-07-22T01:08:48.240233Z","shell.execute_reply.started":"2024-07-22T01:08:48.189771Z","shell.execute_reply":"2024-07-22T01:08:48.239272Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"%%time\ntokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\ntrain_df = pd.read_csv(os.path.join(Data_dir,\"train.csv\")).sample(num_to_load+valid_size,random_state=SEED)\nprint('loaded %d records' % len(train_df))\n\n# Make sure all comment_text values are strings\ntrain_df['comment_text'] = train_df['comment_text'].astype(str) \n\nsequences = convert_lines(train_df[\"comment_text\"].fillna(\"DUMMY_VALUE\"),MAX_SEQUENCE_LENGTH,tokenizer)\ntrain_df=train_df.fillna(0)\n# List all identities\nidentity_columns = [\n    'male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish',\n    'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\ny_columns=['target']\n\ntrain_df = train_df.drop(['comment_text'],axis=1)\n# convert target to 0,1\ntrain_df['target']=(train_df['target']>=0.5).astype(float)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T01:08:48.241687Z","iopub.execute_input":"2024-07-22T01:08:48.242007Z","iopub.status.idle":"2024-07-22T01:43:43.622913Z","shell.execute_reply.started":"2024-07-22T01:08:48.241940Z","shell.execute_reply":"2024-07-22T01:43:43.621917Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"loaded 1100000 records\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=1100000), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2183147ceabb4a028aec32ce150db8a4"}},"metadata":{}},{"name":"stdout","text":"\n24678\nCPU times: user 34min 43s, sys: 15.9 s, total: 34min 59s\nWall time: 34min 55s\n","output_type":"stream"}]},{"cell_type":"code","source":"\nX = sequences[:num_to_load]                \ny = train_df[y_columns].values[:num_to_load]\nX_val = sequences[num_to_load:]              \ny_val = train_df[y_columns].values[num_to_load:]\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T01:43:43.624225Z","iopub.execute_input":"2024-07-22T01:43:43.624504Z","iopub.status.idle":"2024-07-22T01:43:43.706005Z","shell.execute_reply.started":"2024-07-22T01:43:43.624440Z","shell.execute_reply":"2024-07-22T01:43:43.705338Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test_df=train_df.tail(valid_size).copy()\ntrain_df=train_df.head(num_to_load)","metadata":{"execution":{"iopub.status.busy":"2024-07-22T01:43:43.707209Z","iopub.execute_input":"2024-07-22T01:43:43.707514Z","iopub.status.idle":"2024-07-22T01:43:43.769473Z","shell.execute_reply.started":"2024-07-22T01:43:43.707453Z","shell.execute_reply":"2024-07-22T01:43:43.768839Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\n\ntrain_dataset = torch.utils.data.TensorDataset(torch.tensor(X,dtype=torch.long), torch.tensor(y,dtype=torch.float))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T01:43:43.770846Z","iopub.execute_input":"2024-07-22T01:43:43.771089Z","iopub.status.idle":"2024-07-22T01:43:45.413521Z","shell.execute_reply.started":"2024-07-22T01:43:43.771047Z","shell.execute_reply":"2024-07-22T01:43:45.412742Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"output_model_file = \"bert_pytorch.bin\"\n\nlr=2e-5\nbatch_size = 32\naccumulation_steps=2\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\ntorch.backends.cudnn.deterministic = True\n\nmodel = BertForSequenceClassification.from_pretrained(\"../working\",cache_dir=None,num_labels=len(y_columns))\nmodel.zero_grad()\nmodel = model.to(device)\nparam_optimizer = list(model.named_parameters())\nno_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\noptimizer_grouped_parameters = [\n    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n    ]\ntrain = train_dataset\n\nnum_train_optimization_steps = int(EPOCHS*len(train)/batch_size/accumulation_steps)\n\noptimizer = BertAdam(optimizer_grouped_parameters,\n                     lr=lr,\n                     warmup=0.05,\n                     t_total=num_train_optimization_steps)\n\nmodel, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\",verbosity=0)\nmodel=model.train()\n\ntq = tqdm_notebook(range(EPOCHS))\nfor epoch in tq:\n    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n    avg_loss = 0.\n    avg_accuracy = 0.\n    lossf=None\n    tk0 = tqdm_notebook(enumerate(train_loader),total=len(train_loader),leave=False)\n    optimizer.zero_grad()   # Bug fix - thanks to @chinhuic\n    for i,(x_batch, y_batch) in tk0:\n#        optimizer.zero_grad()\n        y_pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n        loss =  F.binary_cross_entropy_with_logits(y_pred,y_batch.to(device))\n        with amp.scale_loss(loss, optimizer) as scaled_loss:\n            scaled_loss.backward()\n        if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n            optimizer.step()                            # Now we can do an optimizer step\n            optimizer.zero_grad()\n        if lossf:\n            lossf = 0.98*lossf+0.02*loss.item()\n        else:\n            lossf = loss.item()\n        tk0.set_postfix(loss = lossf)\n        avg_loss += loss.item() / len(train_loader)\n        avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (y_batch[:,0]>0.5).to(device)).to(torch.float) ).item()/len(train_loader)\n    tq.set_postfix(avg_loss=avg_loss,avg_accuracy=avg_accuracy)\n\n\ntorch.save(model.state_dict(), output_model_file)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T01:43:45.415044Z","iopub.execute_input":"2024-07-22T01:43:45.415383Z","iopub.status.idle":"2024-07-22T07:44:36.410269Z","shell.execute_reply.started":"2024-07-22T01:43:45.415323Z","shell.execute_reply":"2024-07-22T07:44:36.409566Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7a82430bbdd0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=1), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53c5fea9c38b49cc8d0497c5486aff85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=31250), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Run validation\n# The following 2 lines are not needed but show how to download the model for prediction\nmodel = BertForSequenceClassification(bert_config,num_labels=len(y_columns))\nmodel.load_state_dict(torch.load(output_model_file ))\nmodel.to(device)\nfor param in model.parameters():\n    param.requires_grad=False\nmodel.eval()\nvalid_preds = np.zeros((len(X_val)))\nvalid = torch.utils.data.TensorDataset(torch.tensor(X_val,dtype=torch.long))\nvalid_loader = torch.utils.data.DataLoader(valid, batch_size=32, shuffle=False)\n\ntk0 = tqdm_notebook(valid_loader)\nfor i,(x_batch,)  in enumerate(tk0):\n    pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)\n    valid_preds[i*32:(i+1)*32]=pred[:,0].detach().cpu().squeeze().numpy()\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T07:44:36.411631Z","iopub.execute_input":"2024-07-22T07:44:36.411871Z","iopub.status.idle":"2024-07-22T07:56:49.304855Z","shell.execute_reply.started":"2024-07-22T07:44:36.411832Z","shell.execute_reply":"2024-07-22T07:56:49.304071Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1)\n  (classifier): Linear(in_features=768, out_features=1, bias=True)\n)"},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1)\n  (classifier): Linear(in_features=768, out_features=1, bias=True)\n)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=3125), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"844d67c8d78641439195cde02bf63635"}},"metadata":{}},{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# From baseline kernel\n\ndef calculate_overall_auc(df, model_name):\n    true_labels = df[TOXICITY_COLUMN]>0.5\n    predicted_labels = df[model_name]\n    return metrics.roc_auc_score(true_labels, predicted_labels)\n    \ndef power_mean(series, p):\n    total = sum(np.power(series, p))\n    return np.power(total / len(series), 1 / p)\n\ndef get_final_metric(bias_df, overall_auc, POWER=-5, OVERALL_MODEL_WEIGHT=0.25):\n    bias_score = np.average([\n        power_mean(bias_df[SUBGROUP_AUC], POWER),\n        power_mean(bias_df[BPSN_AUC], POWER),\n        power_mean(bias_df[BNSP_AUC], POWER)\n    ])\n    return (OVERALL_MODEL_WEIGHT * overall_auc) + ((1 - OVERALL_MODEL_WEIGHT) * bias_score)\n\n\n\nSUBGROUP_AUC = 'subgroup_auc'\nBPSN_AUC = 'bpsn_auc'  # stands for background positive, subgroup negative\nBNSP_AUC = 'bnsp_auc'  # stands for background negative, subgroup positive\n\ndef compute_auc(y_true, y_pred):\n    try:\n        return metrics.roc_auc_score(y_true, y_pred)\n    except ValueError:\n        return np.nan\n\ndef compute_subgroup_auc(df, subgroup, label, model_name):\n    subgroup_examples = df[df[subgroup]>0.5]\n    return compute_auc((subgroup_examples[label]>0.5), subgroup_examples[model_name])\n\ndef compute_bpsn_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup negative examples and the background positive examples.\"\"\"\n    subgroup_negative_examples = df[(df[subgroup]>0.5) & (df[label]<=0.5)]\n    non_subgroup_positive_examples = df[(df[subgroup]<=0.5) & (df[label]>0.5)]\n    examples = subgroup_negative_examples.append(non_subgroup_positive_examples)\n    return compute_auc(examples[label]>0.5, examples[model_name])\n\ndef compute_bnsp_auc(df, subgroup, label, model_name):\n    \"\"\"Computes the AUC of the within-subgroup positive examples and the background negative examples.\"\"\"\n    subgroup_positive_examples = df[(df[subgroup]>0.5) & (df[label]>0.5)]\n    non_subgroup_negative_examples = df[(df[subgroup]<=0.5) & (df[label]<=0.5)]\n    examples = subgroup_positive_examples.append(non_subgroup_negative_examples)\n    return compute_auc(examples[label]>0.5, examples[model_name])\n\ndef compute_bias_metrics_for_model(dataset,\n                                   subgroups,\n                                   model,\n                                   label_col,\n                                   include_asegs=False):\n    \"\"\"Computes per-subgroup metrics for all subgroups and one model.\"\"\"\n    records = []\n    for subgroup in subgroups:\n        record = {\n            'subgroup': subgroup,\n            'subgroup_size': len(dataset[dataset[subgroup]>0.5])\n        }\n        record[SUBGROUP_AUC] = compute_subgroup_auc(dataset, subgroup, label_col, model)\n        record[BPSN_AUC] = compute_bpsn_auc(dataset, subgroup, label_col, model)\n        record[BNSP_AUC] = compute_bnsp_auc(dataset, subgroup, label_col, model)\n        records.append(record)\n    return pd.DataFrame(records).sort_values('subgroup_auc', ascending=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T07:56:49.306357Z","iopub.execute_input":"2024-07-22T07:56:49.306627Z","iopub.status.idle":"2024-07-22T07:56:49.411489Z","shell.execute_reply.started":"2024-07-22T07:56:49.306576Z","shell.execute_reply":"2024-07-22T07:56:49.410758Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"\nMODEL_NAME = 'model1'\ntest_df[MODEL_NAME]=torch.sigmoid(torch.tensor(valid_preds)).numpy()\nTOXICITY_COLUMN = 'target'\nbias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, 'target')\nbias_metrics_df\nget_final_metric(bias_metrics_df, calculate_overall_auc(test_df, MODEL_NAME))","metadata":{"execution":{"iopub.status.busy":"2024-07-22T07:56:49.412767Z","iopub.execute_input":"2024-07-22T07:56:49.413082Z","iopub.status.idle":"2024-07-22T07:56:50.345028Z","shell.execute_reply.started":"2024-07-22T07:56:49.413021Z","shell.execute_reply":"2024-07-22T07:56:50.344305Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"   bnsp_auc  bpsn_auc      ...       subgroup_auc  subgroup_size\n2  0.970580  0.850340      ...           0.842154            579\n7  0.972660  0.853721      ...           0.848294           1312\n6  0.978164  0.829833      ...           0.855691            744\n5  0.965812  0.893783      ...           0.872753           1076\n4  0.957125  0.921044      ...           0.892779            387\n1  0.960471  0.944279      ...           0.925204           2790\n3  0.951274  0.955246      ...           0.926057           1997\n0  0.968627  0.931659      ...           0.928642           2260\n8  0.981058  0.929391      ...           0.955801            227\n\n[9 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bnsp_auc</th>\n      <th>bpsn_auc</th>\n      <th>subgroup</th>\n      <th>subgroup_auc</th>\n      <th>subgroup_size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0.970580</td>\n      <td>0.850340</td>\n      <td>homosexual_gay_or_lesbian</td>\n      <td>0.842154</td>\n      <td>579</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.972660</td>\n      <td>0.853721</td>\n      <td>white</td>\n      <td>0.848294</td>\n      <td>1312</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.978164</td>\n      <td>0.829833</td>\n      <td>black</td>\n      <td>0.855691</td>\n      <td>744</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.965812</td>\n      <td>0.893783</td>\n      <td>muslim</td>\n      <td>0.872753</td>\n      <td>1076</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.957125</td>\n      <td>0.921044</td>\n      <td>jewish</td>\n      <td>0.892779</td>\n      <td>387</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.960471</td>\n      <td>0.944279</td>\n      <td>female</td>\n      <td>0.925204</td>\n      <td>2790</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.951274</td>\n      <td>0.955246</td>\n      <td>christian</td>\n      <td>0.926057</td>\n      <td>1997</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0.968627</td>\n      <td>0.931659</td>\n      <td>male</td>\n      <td>0.928642</td>\n      <td>2260</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.981058</td>\n      <td>0.929391</td>\n      <td>psychiatric_or_mental_illness</td>\n      <td>0.955801</td>\n      <td>227</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"0.9298784415544122"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}